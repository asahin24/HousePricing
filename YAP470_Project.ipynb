{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86736f77-d0bc-42d6-9985-6500fd2b2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Read the training data\n",
    "import os\n",
    "train_file_path = os.getcwd() + '/house-prices-advanced-regression-techniques/train.csv'\n",
    "test_file_path = os.getcwd() + '/house-prices-advanced-regression-techniques/test.csv'\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a57ff7-8e8f-497c-a52d-70089262341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50eb791-8897-469c-8711-dd223cb1f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/12 21:57:44 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ebda20-ef73-4d75-83dd-6f3247ba4de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of the data\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9594c7-76ab-4b37-b961-c0b194ca2d58",
   "metadata": {},
   "source": [
    "Traing data has 81 columns which is one more than the column number of test data. Extra column is target variable, 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0954c7-0a2c-428e-9e19-ccb190b5dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936e694-50b6-4b0d-8c00-df651825cbf5",
   "metadata": {},
   "source": [
    "Make data preprocessings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35578643-d3b2-44e2-98f3-4b5b899e12f6",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df19cb8c-5a0d-409b-a453-1c0c80c0d78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features with null values in training data : 19\n",
      "Features with null values in training data :\n",
      "LotFrontage\n",
      "Alley\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Electrical\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "\n",
      "\n",
      "\n",
      "# of features with null values in test data : 33\n",
      "Features with null values in test data :\n",
      "MSZoning\n",
      "LotFrontage\n",
      "Alley\n",
      "Utilities\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinSF1\n",
      "BsmtFinType2\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageCars\n",
      "GarageArea\n",
      "GarageQual\n",
      "GarageCond\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "SaleType\n"
     ]
    }
   ],
   "source": [
    "train_data_features_with_null = []\n",
    "for feature in train_data:\n",
    "    if train_data[feature].isna().sum() > 0:\n",
    "        train_data_features_with_null.append(feature)\n",
    "\n",
    "test_data_features_with_null = []\n",
    "for feature in test_data:\n",
    "    if test_data[feature].isna().sum() > 0:\n",
    "        test_data_features_with_null.append(feature)\n",
    "\n",
    "print('# of features with null values in training data :', len(train_data_features_with_null))\n",
    "print('Features with null values in training data :', *train_data_features_with_null,sep='\\n')\n",
    "print('\\n\\n')\n",
    "print('# of features with null values in test data :', len(test_data_features_with_null))\n",
    "print('Features with null values in test data :', *test_data_features_with_null,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6419a49-eda3-4fe6-b03a-3042813654f0",
   "metadata": {},
   "source": [
    "Check for the features which have null values in both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbaf9c3-0561-497e-9990-ec935495cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of common features containing null values : 18\n",
      "Common features containing null values :\n",
      "LotFrontage\n",
      "Alley\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n"
     ]
    }
   ],
   "source": [
    "common_features_with_null = []\n",
    "for feature in train_data_features_with_null:\n",
    "    if feature in test_data_features_with_null:\n",
    "        common_features_with_null.append(feature)\n",
    "\n",
    "print('# of common features containing null values :', len(common_features_with_null))\n",
    "\n",
    "print('Common features containing null values :', *common_features_with_null, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4d778-2c02-4da9-b085-dcd0654855e8",
   "metadata": {},
   "source": [
    "Calculate percentages of missing values in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820a2d34-2505-4297-8f23-c70fea0fd2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolQC  \t\t:  0.9952054794520548\n",
      "MiscFeature  \t\t:  0.963013698630137\n",
      "Alley  \t\t:  0.9376712328767123\n",
      "Fence  \t\t:  0.8075342465753425\n",
      "FireplaceQu  \t\t:  0.4726027397260274\n",
      "LotFrontage  \t\t:  0.1773972602739726\n",
      "GarageType  \t\t:  0.05547945205479452\n",
      "GarageYrBlt  \t\t:  0.05547945205479452\n",
      "GarageFinish  \t\t:  0.05547945205479452\n",
      "GarageQual  \t\t:  0.05547945205479452\n",
      "GarageCond  \t\t:  0.05547945205479452\n",
      "BsmtExposure  \t\t:  0.026027397260273973\n",
      "BsmtFinType2  \t\t:  0.026027397260273973\n",
      "BsmtQual  \t\t:  0.025342465753424658\n",
      "BsmtCond  \t\t:  0.025342465753424658\n",
      "BsmtFinType1  \t\t:  0.025342465753424658\n",
      "MasVnrType  \t\t:  0.005479452054794521\n",
      "MasVnrArea  \t\t:  0.005479452054794521\n",
      "Electrical  \t\t:  0.0006849315068493151\n"
     ]
    }
   ],
   "source": [
    "nan_percent_train = {col : train_data[col].isnull().mean() for col in train_data.columns}\n",
    "nan_percent_train = dict(sorted(nan_percent_train.items(), key = lambda x: x[1], reverse = True))\n",
    "# Remove features with 0 percent nan values from this list.\n",
    "new_nan_percent_train = {}\n",
    "for (key, value) in nan_percent_train.items():\n",
    "    if value > 0:\n",
    "        new_nan_percent_train[key] = value\n",
    "nan_percent_train = new_nan_percent_train\n",
    "\n",
    "# Print these features\n",
    "for key in nan_percent_train.keys():\n",
    "    print(key,' \\t\\t: ',nan_percent_train[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f49767-28e0-40d0-b7d8-0f750b3ab995",
   "metadata": {},
   "source": [
    "Calculate percentage of missing values in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5ef346-e078-4663-8057-939d24be16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolQC  \t\t:  0.997943797121316\n",
      "MiscFeature  \t\t:  0.9650445510623715\n",
      "Alley  \t\t:  0.9266620973269363\n",
      "Fence  \t\t:  0.8012337217272104\n",
      "FireplaceQu  \t\t:  0.5003427004797807\n",
      "LotFrontage  \t\t:  0.15558601782042494\n",
      "GarageYrBlt  \t\t:  0.053461274845784786\n",
      "GarageFinish  \t\t:  0.053461274845784786\n",
      "GarageQual  \t\t:  0.053461274845784786\n",
      "GarageCond  \t\t:  0.053461274845784786\n",
      "GarageType  \t\t:  0.0520904729266621\n",
      "BsmtCond  \t\t:  0.030843043180260453\n",
      "BsmtQual  \t\t:  0.03015764222069911\n",
      "BsmtExposure  \t\t:  0.03015764222069911\n",
      "BsmtFinType1  \t\t:  0.02878684030157642\n",
      "BsmtFinType2  \t\t:  0.02878684030157642\n",
      "MasVnrType  \t\t:  0.010966415352981495\n",
      "MasVnrArea  \t\t:  0.01028101439342015\n",
      "MSZoning  \t\t:  0.0027416038382453737\n",
      "Utilities  \t\t:  0.0013708019191226869\n",
      "BsmtFullBath  \t\t:  0.0013708019191226869\n",
      "BsmtHalfBath  \t\t:  0.0013708019191226869\n",
      "Functional  \t\t:  0.0013708019191226869\n",
      "Exterior1st  \t\t:  0.0006854009595613434\n",
      "Exterior2nd  \t\t:  0.0006854009595613434\n",
      "BsmtFinSF1  \t\t:  0.0006854009595613434\n",
      "BsmtFinSF2  \t\t:  0.0006854009595613434\n",
      "BsmtUnfSF  \t\t:  0.0006854009595613434\n",
      "TotalBsmtSF  \t\t:  0.0006854009595613434\n",
      "KitchenQual  \t\t:  0.0006854009595613434\n",
      "GarageCars  \t\t:  0.0006854009595613434\n",
      "GarageArea  \t\t:  0.0006854009595613434\n",
      "SaleType  \t\t:  0.0006854009595613434\n"
     ]
    }
   ],
   "source": [
    "nan_percent_test = {col : test_data[col].isnull().mean() for col in test_data.columns}\n",
    "nan_percent_test = dict(sorted(nan_percent_test.items(), key = lambda x: x[1], reverse = True))\n",
    "# Remove features with 0 percent nan values from this list.\n",
    "new_nan_percent_test = {}\n",
    "for (key, value) in nan_percent_test.items():\n",
    "    if value > 0:\n",
    "        new_nan_percent_test[key] = value\n",
    "nan_percent_test = new_nan_percent_test\n",
    "\n",
    "# Print these features\n",
    "for key in nan_percent_test.keys():\n",
    "    print(key,' \\t\\t: ',nan_percent_test[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a254a-8543-4848-a862-7df31cf2e792",
   "metadata": {},
   "source": [
    "Drop the features with percentage of nan values greater than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed94d88-0c6d-44e3-aa74-9523cda9231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_nan_percent = {}\n",
    "for (key, value) in nan_percent_train.items():\n",
    "    if value > 0.5:\n",
    "        high_nan_percent[key] = value\n",
    "        \n",
    "for (key, value) in nan_percent_test.items():\n",
    "    if value > 0.5:\n",
    "        high_nan_percent[key] = value\n",
    "\n",
    "# Remove the keys from full lists\n",
    "for key in high_nan_percent.keys():\n",
    "    nan_percent_train.pop(key)\n",
    "    nan_percent_test.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523d0b31-7020-430f-a619-17f145750016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.997943797121316, 0.9650445510623715, 0.9266620973269363, 0.8012337217272104, 0.5003427004797807])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.log_param(\"Parameters with high percentage of NaN values\", high_nan_percent.keys())\n",
    "mlflow.log_param(\"Percentages of NaN values\", high_nan_percent.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a75856-2f4f-40c5-ac76-9dab9ecff541",
   "metadata": {},
   "source": [
    "Drop the features with high percentage of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f449e8-602c-46b6-af35-dfdba91de6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_train_data = train_data.drop(list(high_nan_percent), axis = 'columns')\n",
    "reduced_test_data = test_data.drop(list(high_nan_percent), axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41514384-3968-4200-9aa2-6acd6e2f6f8f",
   "metadata": {},
   "source": [
    "Impute training data and test data. Numeric features will be imputed by \"mean\" while categorical features will be imputed by \"mode\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23efd7a5-e00b-4b76-9e82-3131a95c2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 76)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "print(reduced_train_data.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87dc9714-e8ee-4cfa-8942-0d970bbd3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "my_numeric_imputer = SimpleImputer()\n",
    "my_categorical_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# Before imputation, select training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(reduced_train_data, y, train_size=0.8,\n",
    "                                                      test_size=0.2, random_state=0)\n",
    "X_test = reduced_test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb8421-97dd-4d2e-9957-2127dc982955",
   "metadata": {},
   "source": [
    "# Seperate numerical and categorical features\n",
    "\n",
    "num_X_train = X_train.select_dtypes(exclude = 'object')\n",
    "num_X_valid = X_valid.select_dtypes(exclude = 'object')\n",
    "num_X_test = reduced_test_data.select_dtypes(exclude = 'object')\n",
    "\n",
    "cat_X_train = X_train.select_dtypes(include = 'object')\n",
    "cat_X_valid = X_valid.select_dtypes(include = 'object')\n",
    "cat_X_test = reduced_test_data.select_dtypes(include = 'object')\n",
    "\n",
    "# Impute missing values in numerical data with mean values\n",
    "imputed_num_X_train = pd.DataFrame(my_numeric_imputer.fit_transform(num_X_train))\n",
    "imputed_num_X_valid = pd.DataFrame(my_numeric_imputer.transform(num_X_valid))\n",
    "imputed_num_X_test = pd.DataFrame(my_numeric_imputer.transform(num_X_test))\n",
    "\n",
    "imputed_cat_X_train = pd.DataFrame(my_categorical_imputer.fit_transform(cat_X_train))\n",
    "imputed_cat_X_valid = pd.DataFrame(my_categorical_imputer.transform(cat_X_valid))\n",
    "imputed_cat_X_test = pd.DataFrame(my_categorical_imputer.transform(cat_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c6271-1854-4eff-9ccf-4f000f1b8a95",
   "metadata": {},
   "source": [
    "Check if there is any missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05f4f1-00da-474e-9cd2-76b8069d87f7",
   "metadata": {},
   "source": [
    "print(\"# of missing values in imputed_num_X_train\\t:\", imputed_num_X_train.isnull().sum().sum() )\n",
    "print(\"# of missing values in imputed_num_X_valid\\t:\", imputed_num_X_valid.isnull().sum().sum() )\n",
    "print(\"# of missing values in imputed_num_X_test\\t:\", imputed_num_X_test.isnull().sum().sum() )\n",
    "print(\"# of missing values in imputed_cat_X_train\\t:\", imputed_cat_X_train.isnull().sum().sum() )\n",
    "print(\"# of missing values in imputed_cat_X_valid\\t:\", imputed_cat_X_valid.isnull().sum().sum() )\n",
    "print(\"# of missing values in imputed_cat_X_test\\t:\", imputed_cat_X_test.isnull().sum().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554fe12-9cc9-41f2-9bb3-789dabafab70",
   "metadata": {},
   "source": [
    "print(imputed_num_X_train.shape)\n",
    "print(imputed_cat_X_train.shape)\n",
    "print(imputed_num_X_test.shape)\n",
    "print(imputed_cat_X_test.shape)\n",
    "print(imputed_num_X_valid.shape)\n",
    "print(imputed_cat_X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e579e-d0d4-4a19-b7a1-c4b837fe1573",
   "metadata": {},
   "source": [
    "Now, concatenate numerical and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951fc4f-34df-4cc3-9cd5-6cfa1f8ff215",
   "metadata": {},
   "source": [
    "imputed_X_train = pd.concat([imputed_num_X_train, imputed_cat_X_train], axis = 1)\n",
    "imputed_X_test = pd.concat([imputed_num_X_test, imputed_cat_X_test], axis = 1)\n",
    "imputed_X_valid = pd.concat([imputed_num_X_valid, imputed_cat_X_valid], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b401336-d29d-4296-bb0a-f280b0c49475",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SalePrice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\90543\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\users\\90543\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\90543\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SalePrice'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     imputed_X_train[label]\u001b[38;5;241m.\u001b[39mfillna(imputed_X_train[label]\u001b[38;5;241m.\u001b[39mmean(), inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mimputed_X_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(imputed_X_train[label]\u001b[38;5;241m.\u001b[39mmean(), inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\90543\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\users\\90543\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SalePrice'"
     ]
    }
   ],
   "source": [
    "imputed_X_train = X_train.copy()\n",
    "imputed_X_test = X_test.copy()\n",
    "imputed_X_valid = X_valid.copy()\n",
    "\n",
    "for label,_ in imputed_X_train.items():\n",
    "    if imputed_X_train[label].dtype == 'object':\n",
    "        imputed_X_train[label].fillna(imputed_X_train[label].mode()[0], inplace = True)\n",
    "        imputed_X_test[label].fillna(imputed_X_train[label].mode()[0], inplace = True)\n",
    "    else:\n",
    "        imputed_X_train[label].fillna(imputed_X_train[label].mean(), inplace = True)\n",
    "        imputed_X_test[label].fillna(imputed_X_train[label].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c1417-f5de-43ee-a6e5-5d9a20ce5c04",
   "metadata": {},
   "source": [
    "Apply ordinal encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504cccb-76a3-4c6c-819a-21dcb3d5dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f22d4d-a013-495f-8d48-f155f73f82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "label_X_test = X_test.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "label_X_test[object_cols] = ordinal_encoder.transform(X_test[object_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e3e26-8e21-471d-910f-cd2576834615",
   "metadata": {},
   "source": [
    "Now look at correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9559d9b-5cb8-4979-a3fe-03deced20e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = label_X_train.corr()\n",
    "# Filter the features whose correlation with \"SalePrice\" is higher than 0.5\n",
    "highest_corr_features = corr.index[abs(corr['SalePrice']) > 0.5]\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "g = sns.heatmap(label_X_train[highest_corr_features].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9970630-09b8-45f9-8c1c-905c65886e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_figure(fig1, \"Abs_correlation_matrix.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5514de1-ace2-4a12-9369-831cfa3f4d3a",
   "metadata": {},
   "source": [
    "Sort the correlation matrix to see the features that are most related to 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a2824-0f2c-4b51-a523-402a82dca782",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_corr = label_X_train[highest_corr_features].corr()\n",
    "sorted_corr = highest_corr.abs().sort_values('SalePrice', ascending = False)\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "g = sns.heatmap(sorted_corr, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d7e4c-84e9-4068-aed0-a1a2b0620582",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sorted = ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea',\n",
    "                 'TotalBsmtSF', 'ExterQual', '1stFlrSF', 'BsmtQual', 'KitchenQual',\n",
    "                 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519e6d4-d841-4ce7-9b0f-90850a432f4c",
   "metadata": {},
   "source": [
    "If there are columns that are highly correlated to each other, drop one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ab0ac-2952-4048-9262-7d6ace0b364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features_sorted = features_sorted.copy()\n",
    "for col in features_sorted:\n",
    "    for index in features_sorted:\n",
    "        if col != index and highest_corr[col][index] > 0.8:\n",
    "            if col in clean_features_sorted:\n",
    "                clean_features_sorted.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f2b52-cbec-4d29-a56b-d449141ca1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_features_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ed083-c2f5-44e2-bf65-3ed498e8ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_label_X_train = label_X_train[clean_features_sorted];\n",
    "reduced_label_X_test = label_X_test[clean_features_sorted];\n",
    "reduced_label_X_valid = label_X_test[clean_features_sorted];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5a3d0-6130-47db-9ef2-9c34efd0740f",
   "metadata": {},
   "source": [
    "Apply ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282073c-7d78-4199-a265-734bead5c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF = RandomForestRegressor(bootstrap = True, random_state = 12345)\n",
    "\n",
    "RF.fit(label_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c607a-810e-40d6-9599-ef304c421bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
